{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, the ETL process for our company project, <b><i>Tender data Insight</b></i>, is a bit different from normal ETL process.\n",
    "\n",
    "The data is in extremly poor quality due to the fact that the data is collected in pdf file then being converted into excel file, which will have lots of incorrect data.\n",
    "\n",
    "This leads to lots of resources for the cleaning data process. Thus, after every finished cleaning process, the data will be loaded back into the database to prevent repeated process.\n",
    "\n",
    "ETL Steps:\n",
    "1. Import libraries\n",
    "2. Explore the dataset\n",
    "3. Data processing\n",
    "4. Update/Load data back to SQL Server\n",
    "5. Complete code (incl for loop)\n",
    "**From step 1 to step 4: it will highlight the process to perform ETL process for one dataset that need to be update, however in step 5 it will include all the previous steps in order to perform ETL for numerous files that need to be loaded back to the database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "import calendar\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pypyodbc as pyodbc\n",
    "from sqlalchemy import create_engine # pip install SQLAlchemy\n",
    "import sqlalchemy\n",
    "from sqlalchemy.engine import URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Explore the data that need to be updated**\n",
    "\n",
    "In each file, there is two sheets equivalent to two tables need to be updated or loaded back to SQL Server<br>\n",
    "- The first: the hospital tender inviting data<br>\n",
    "- The second: the hospital tender winning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.read_excel(r'C:\\JNJ_TDI_11_2023.xlsx',sheet_name='Result')\n",
    "df_inviting = pd.read_excel(r'C:\\JNJ_TDI_11_2023.xlsx',sheet_name='Inviting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Include/Exclude</th>\n",
       "      <th>Note</th>\n",
       "      <th>ATC3</th>\n",
       "      <th>FormulaName</th>\n",
       "      <th>Molecule</th>\n",
       "      <th>Dosage</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Visa</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>...</th>\n",
       "      <th>AllocatedName</th>\n",
       "      <th>Province</th>\n",
       "      <th>Region</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>ResultDate</th>\n",
       "      <th>ValidTo</th>\n",
       "      <th>TenderYear</th>\n",
       "      <th>TenderQuotationType</th>\n",
       "      <th>Status</th>\n",
       "      <th>Note_AIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112023_491_R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N05A</td>\n",
       "      <td>ARIPIPRAZOLE 5MG TAB</td>\n",
       "      <td>ARIPIPRAZOLE</td>\n",
       "      <td>5MG</td>\n",
       "      <td>POZIATS 5MG</td>\n",
       "      <td>QLDB-683-18</td>\n",
       "      <td>CONG TY CP DUOC PHAM MEDISUN</td>\n",
       "      <td>...</td>\n",
       "      <td>BV AN BINH</td>\n",
       "      <td>HCMCT</td>\n",
       "      <td>HCMCT</td>\n",
       "      <td>2023-06-23</td>\n",
       "      <td>2023-10-18</td>\n",
       "      <td>2024-06-22</td>\n",
       "      <td>2023</td>\n",
       "      <td>New Tender</td>\n",
       "      <td>RAW</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112023_610_R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N05A</td>\n",
       "      <td>OLANZAPINE 10MG TAB</td>\n",
       "      <td>OLANZAPINE</td>\n",
       "      <td>10MG</td>\n",
       "      <td>ZANOBAPINE 10</td>\n",
       "      <td>VN-16470-13</td>\n",
       "      <td>MEPRO PHARMACEUTICALS</td>\n",
       "      <td>...</td>\n",
       "      <td>BV AN BINH</td>\n",
       "      <td>HCMCT</td>\n",
       "      <td>HCMCT</td>\n",
       "      <td>2023-06-23</td>\n",
       "      <td>2023-10-18</td>\n",
       "      <td>2024-06-22</td>\n",
       "      <td>2023</td>\n",
       "      <td>New Tender</td>\n",
       "      <td>RAW</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  Include/Exclude Note  ATC3           FormulaName  \\\n",
       "0  112023_491_R              NaN  NaN  N05A  ARIPIPRAZOLE 5MG TAB   \n",
       "1  112023_610_R              NaN  NaN  N05A   OLANZAPINE 10MG TAB   \n",
       "\n",
       "       Molecule Dosage    ProductName         Visa  \\\n",
       "0  ARIPIPRAZOLE    5MG    POZIATS 5MG  QLDB-683-18   \n",
       "1    OLANZAPINE   10MG  ZANOBAPINE 10  VN-16470-13   \n",
       "\n",
       "                   Manufacturer  ... AllocatedName Province Region ClosedDate  \\\n",
       "0  CONG TY CP DUOC PHAM MEDISUN  ...    BV AN BINH    HCMCT  HCMCT 2023-06-23   \n",
       "1         MEPRO PHARMACEUTICALS  ...    BV AN BINH    HCMCT  HCMCT 2023-06-23   \n",
       "\n",
       "   ResultDate    ValidTo  TenderYear TenderQuotationType Status Note_AIS  \n",
       "0  2023-10-18 2024-06-22        2023          New Tender    RAW      NaN  \n",
       "1  2023-10-18 2024-06-22        2023          New Tender    RAW      NaN  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Include/Exclude</th>\n",
       "      <th>Note</th>\n",
       "      <th>ATC3</th>\n",
       "      <th>FormulaName</th>\n",
       "      <th>Molecule</th>\n",
       "      <th>Dosage</th>\n",
       "      <th>UnitOfMeasure</th>\n",
       "      <th>Quota(SmallestUnit)</th>\n",
       "      <th>TenderPackage</th>\n",
       "      <th>...</th>\n",
       "      <th>HospitalName</th>\n",
       "      <th>Province</th>\n",
       "      <th>Region</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>ResultDate</th>\n",
       "      <th>ValidTo</th>\n",
       "      <th>TenderYear</th>\n",
       "      <th>TenderQuotationType</th>\n",
       "      <th>Status</th>\n",
       "      <th>Note_AIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112023_138_I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N05A</td>\n",
       "      <td>OLANZAPINE 10MG TAB</td>\n",
       "      <td>OLANZAPINE</td>\n",
       "      <td>10MG</td>\n",
       "      <td>TABLET</td>\n",
       "      <td>300000</td>\n",
       "      <td>GENERIC 3</td>\n",
       "      <td>...</td>\n",
       "      <td>BV TAM THAN TINH HA NAM</td>\n",
       "      <td>HANAM</td>\n",
       "      <td>NORTH</td>\n",
       "      <td>2023-09-22</td>\n",
       "      <td>2023-09-22</td>\n",
       "      <td>2024-10-05</td>\n",
       "      <td>2023</td>\n",
       "      <td>Direct contracting</td>\n",
       "      <td>RAW</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112023_139_I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N05A</td>\n",
       "      <td>QUETIAPINE 100MG TAB</td>\n",
       "      <td>QUETIAPINE</td>\n",
       "      <td>100MG</td>\n",
       "      <td>TABLET</td>\n",
       "      <td>30000</td>\n",
       "      <td>GENERIC 4</td>\n",
       "      <td>...</td>\n",
       "      <td>BV TAM THAN TINH HA NAM</td>\n",
       "      <td>HANAM</td>\n",
       "      <td>NORTH</td>\n",
       "      <td>2023-09-22</td>\n",
       "      <td>2023-09-22</td>\n",
       "      <td>2024-10-05</td>\n",
       "      <td>2023</td>\n",
       "      <td>Direct contracting</td>\n",
       "      <td>RAW</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  Include/Exclude Note  ATC3           FormulaName    Molecule  \\\n",
       "0  112023_138_I              NaN  NaN  N05A   OLANZAPINE 10MG TAB  OLANZAPINE   \n",
       "1  112023_139_I              NaN  NaN  N05A  QUETIAPINE 100MG TAB  QUETIAPINE   \n",
       "\n",
       "  Dosage UnitOfMeasure  Quota(SmallestUnit) TenderPackage  ...  \\\n",
       "0   10MG        TABLET               300000     GENERIC 3  ...   \n",
       "1  100MG        TABLET                30000     GENERIC 4  ...   \n",
       "\n",
       "              HospitalName Province  Region ClosedDate ResultDate    ValidTo  \\\n",
       "0  BV TAM THAN TINH HA NAM    HANAM   NORTH 2023-09-22 2023-09-22 2024-10-05   \n",
       "1  BV TAM THAN TINH HA NAM    HANAM   NORTH 2023-09-22 2023-09-22 2024-10-05   \n",
       "\n",
       "  TenderYear TenderQuotationType Status  Note_AIS  \n",
       "0       2023  Direct contracting    RAW       NaN  \n",
       "1       2023  Direct contracting    RAW       NaN  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inviting.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set data connection to SQL Server\n",
    "cnxn_str = (\"Driver={SQL Server Native Client 11.0};\"\n",
    "            \"Server={SERVER NAME};\"\n",
    "            \"Database={DATABASE NAME};\"\n",
    "            \"UID={USER ID};\"\n",
    "            'PWD={PASSWORD};'\n",
    "        )\n",
    "cnxn = pyodbc.connect(cnxn_str)\n",
    "cursor = cnxn.cursor()\n",
    "connection_url = URL.create('mssql+pyodbc', query={'odbc_connect': cnxn_str})\n",
    "enigne = create_engine(connection_url, module=pyodbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Data Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having said before, this data set is in extremely poor quality and needed a team to perform data cleaning. That being so, this cleaning process step involves lots of Excel operation like: <i>Fill down (Ctrl D), Sort column, vlookup, etc<i>, which is easily can mess up with the whole dataset by messing up the ID column.\n",
    "\n",
    "For that particular reason, we have to do data processing to transform data and eliminate those causes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA\n",
    "df_result.drop_duplicates(subset=['ID'], inplace=True)\n",
    "df_result.rename(columns={'ID':'id'},inplace=True)\n",
    "df_result[f'key_update_{type}'] = df_result['Quota(SmallestUnit)'].astype(str) + '_' + df_result['QuotationID'].astype(str)\n",
    "df_result[f'key_update_{type}'] = df_result['Quota(SmallestUnit)'].astype(str) + '_' + df_result['QuotationID'].astype(str)\n",
    "df_result['Status'] = f'Update_{datetime.now().strftime(\"%Y%m%d\")}' #set the Status column for tracking update date\n",
    "df_result['Source_Update'] = f'{datetime.now().strftime(\"%Y%m%d\")}_' + f[:-5] #set the SourceName column for tracking the source name update\n",
    "df_result.drop(['ClosedDate','ResultDate','ValidTo'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra all the orginal records in the dataframe from SQL database to check if the ID column is swaped or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set data connection to SQL Server\n",
    "cnxn_str = (\"Driver={SQL Server Native Client 11.0};\"\n",
    "            \"Server={SERVER NAME};\"\n",
    "            \"Database={DATABASE NAME};\"\n",
    "            \"UID={USER ID};\"\n",
    "            'PWD={PASSWORD};'\n",
    "        )\n",
    "cnxn = pyodbc.connect(cnxn_str)\n",
    "cursor = cnxn.cursor()\n",
    "connection_url = URL.create('mssql+pyodbc', query={'odbc_connect': cnxn_str})\n",
    "enigne = create_engine(connection_url, module=pyodbc)\n",
    "\n",
    "#import data to sql to take out specific dataset that need to update\n",
    "df_result.to_sql('Update_Result', con=enigne, if_exists='replace', index=False)\n",
    "\n",
    "#export desired dataset to python\n",
    "sql_Result = 'SELECT [ID],[Quota(SmallestUnit)],[QuotationID] FROM TDI_TenderResult WHERE ID IN (SELECT ID FROM Update_Result) AND [Include/Exclude] IS NULL'\n",
    "sql = pd.read_sql(sql_Result, cnxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to check the status of the ID column, we create a new key column by concating the [Quota(SmallestUnit)] and the [QuotationID] in both dataframe (df_result and SQL Server). Then we will merge the new key column from SQL to the df_result. If the two values are equal we will mark that record as <b>\"1\"</b> and <b>\"0\"</b> for not equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create key ID to verify data accuracy that is about to be updated to sql database\n",
    "sql[f'key_sql_{type}'] = sql['quota(smallestunit)'].astype(str) + '_' + sql['quotationid'].astype(str)\n",
    "sql[f'key_sql_{type}'] = sql[f'key_sql_{type}'].str.replace('None','0', regex=True)\n",
    "df_result = pd.merge(df_result,sql[['id',f'key_sql_{type}']],on='id',how='left')\n",
    "df_result = df_result[df_result[f'key_sql_{type}'].notna()]\n",
    "df_result['match'] = np.where(df_result[f'key_sql_{type}'] == df_result[f'key_update_{type}'],1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we will check if the df_result has more than 90% of all the key matching, we can assume the rest 10% is a valid difference. Else if the df_result has less than 90% of matching key, we will eliminate all the records that are marked \"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if data accuracy equal or bigger than 90% then keeping the whole dataset or else delete inaccurcy records\n",
    "if df_result.match.sum()/df_result.id.count() < 0.9:\n",
    "    update = df_result[df_result['match']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Update/Load data to SQL Server**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_update_Result = \"\"\"UPDATE TDI_TenderResult\n",
    "    SET TDI_TenderResult.ATC3 = Update_Result.ATC3,\n",
    "            TDI_TenderResult.Molecule = Update_Result.Molecule,\n",
    "            TDI_TenderResult.FormulaName = Update_Result.FormulaName,\n",
    "            TDI_TenderResult.ProductName = Update_Result.ProductName,\n",
    "            TDI_TenderResult.Dosage = Update_Result.Dosage,\n",
    "            TDI_TenderResult.Visa = Update_Result.Visa,\n",
    "            TDI_TenderResult.Manufacturer = Update_Result.Manufacturer,\n",
    "            TDI_TenderResult.Nation = Update_Result.Nation,\n",
    "            TDI_TenderResult.Presentation = Update_Result.Presentation,\n",
    "            TDI_TenderResult.InDetail = Update_Result.InDetail,\n",
    "            TDI_TenderResult.UnitOfMeasure = Update_Result.UnitOfMeasure,\n",
    "            TDI_TenderResult.[Quota(SmallestUnit)] = Update_Result.[Quota(SmallestUnit)],\n",
    "            TDI_TenderResult.Price = Update_Result.Price,\n",
    "            TDI_TenderResult.[Value] = Update_Result.[Value],\n",
    "            TDI_TenderResult.Contractor = Update_Result.Contractor,\n",
    "            TDI_TenderResult.TenderPackage = Update_Result.TenderPackage,\n",
    "            TDI_TenderResult.HospitalCode = Update_Result.HospitalCode,\n",
    "            TDI_TenderResult.HospitalName = Update_Result.HospitalName,\n",
    "            TDI_TenderResult.AllocatedCode = Update_Result.AllocatedCode,\n",
    "            TDI_TenderResult.AllocatedName = Update_Result.AllocatedName,\n",
    "            TDI_TenderResult.Province = Update_Result.Province,\n",
    "            TDI_TenderResult.Region = Update_Result.Region,\n",
    "            TDI_TenderResult.TenderYear = Update_Result.TenderYear,\n",
    "            TDI_TenderResult.TenderQuotationType = Update_Result.TenderQuotationType,\n",
    "            TDI_TenderResult.[Status] = Update_Result.[Status],\n",
    "            TDI_TenderResult.Note_AIS =  Update_Result.Note_AIS,\n",
    "            TDI_TenderResult.Source_Update = Update_Result.Source_Update \n",
    "    FROM TDI_TenderResult\n",
    "    INNER JOIN Update_Result\n",
    "    ON TDI_TenderResult.ID = Update_Result.ID\n",
    "    DROP TABLE Update_Result\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the verified dataset to SQL\n",
    "update.to_sql(f'Update_{type}', con=enigne, if_exists='replace', index=False)\n",
    "#update the verifed dataset to SQL databse\n",
    "cursor.execute(sql_update_Result)\n",
    "cnxn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The process is the same for the df_iniviting. Full detail view in the complete code in the <b><u>Summary</b></u> part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<b><u>Complete Code (incl for loop)<u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "import calendar\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pypyodbc as pyodbc\n",
    "from sqlalchemy import create_engine # pip install SQLAlchemy\n",
    "import sqlalchemy\n",
    "from sqlalchemy.engine import URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxn_str = (\"Driver={SQL Server Native Client 11.0};\"\n",
    "            \"Server=VNSGNHECDWH01P;\"\n",
    "            \"Database=Tender_Insight;\"\n",
    "            \"UID=HEC_PBI1;\"\n",
    "            'PWD=doordie@2023_2;'\n",
    "        )\n",
    "cnxn = pyodbc.connect(cnxn_str)\n",
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_Result = 'SELECT [ID],[Quota(SmallestUnit)],[QuotationID] FROM TDI_TenderResult WHERE ID IN (SELECT ID FROM Update_Result) AND [Include/Exclude] IS NULL'\n",
    "\n",
    "sql_Inviting = 'SELECT [ID],[Quota(SmallestUnit)],[QuotationID] FROM TDI_TenderInviting WHERE ID IN (SELECT ID FROM Update_Inviting) AND [Include/Exclude] IS NULL'\n",
    "\n",
    "sql_update_Result = \"\"\"UPDATE TDI_TenderResult\n",
    "    SET TDI_TenderResult.ATC3 = Update_Result.ATC3,\n",
    "            TDI_TenderResult.Molecule = Update_Result.Molecule,\n",
    "            TDI_TenderResult.FormulaName = Update_Result.FormulaName,\n",
    "            TDI_TenderResult.ProductName = Update_Result.ProductName,\n",
    "            TDI_TenderResult.Dosage = Update_Result.Dosage,\n",
    "            TDI_TenderResult.Visa = Update_Result.Visa,\n",
    "            TDI_TenderResult.Manufacturer = Update_Result.Manufacturer,\n",
    "            TDI_TenderResult.Nation = Update_Result.Nation,\n",
    "            TDI_TenderResult.Presentation = Update_Result.Presentation,\n",
    "            TDI_TenderResult.InDetail = Update_Result.InDetail,\n",
    "            TDI_TenderResult.UnitOfMeasure = Update_Result.UnitOfMeasure,\n",
    "            TDI_TenderResult.[Quota(SmallestUnit)] = Update_Result.[Quota(SmallestUnit)],\n",
    "            TDI_TenderResult.Price = Update_Result.Price,\n",
    "            TDI_TenderResult.[Value] = Update_Result.[Value],\n",
    "            TDI_TenderResult.Contractor = Update_Result.Contractor,\n",
    "            TDI_TenderResult.TenderPackage = Update_Result.TenderPackage,\n",
    "            TDI_TenderResult.HospitalCode = Update_Result.HospitalCode,\n",
    "            TDI_TenderResult.HospitalName = Update_Result.HospitalName,\n",
    "            TDI_TenderResult.AllocatedCode = Update_Result.AllocatedCode,\n",
    "            TDI_TenderResult.AllocatedName = Update_Result.AllocatedName,\n",
    "            TDI_TenderResult.Province = Update_Result.Province,\n",
    "            TDI_TenderResult.Region = Update_Result.Region,\n",
    "            TDI_TenderResult.TenderYear = Update_Result.TenderYear,\n",
    "            TDI_TenderResult.TenderQuotationType = Update_Result.TenderQuotationType,\n",
    "            TDI_TenderResult.[Status] = Update_Result.[Status],\n",
    "            TDI_TenderResult.Note_AIS =  Update_Result.Note_AIS,\n",
    "            TDI_TenderResult.Source_Update = Update_Result.Source_Update \n",
    "    FROM TDI_TenderResult\n",
    "    INNER JOIN Update_Result\n",
    "    ON TDI_TenderResult.ID = Update_Result.ID\n",
    "    DROP TABLE Update_Result\"\"\"\n",
    "\n",
    "sql_update_Inviting = \"\"\"UPDATE TDI_TenderInviting\n",
    "        SET TDI_TenderInviting.ATC3 = Update_Inviting.ATC3,\n",
    "            TDI_TenderInviting.Molecule = Update_Inviting.Molecule,\n",
    "            TDI_TenderInviting.FormulaName = Update_Inviting.FormulaName,\n",
    "            TDI_TenderInviting.Dosage = Update_Inviting.Dosage,\n",
    "            TDI_TenderInviting.UnitOfMeasure = Update_Inviting.UnitOfMeasure,\n",
    "            TDI_TenderInviting.[Quota(SmallestUnit)] = Update_Inviting.[Quota(SmallestUnit)],\n",
    "            TDI_TenderInviting.TenderPackage = Update_Inviting.TenderPackage,\n",
    "            TDI_TenderInviting.HospitalCode = Update_Inviting.HospitalCode,\n",
    "            TDI_TenderInviting.HospitalName = Update_Inviting.HospitalName,\n",
    "            TDI_TenderInviting.Province = Update_Inviting.Province,\n",
    "            TDI_TenderInviting.Region = Update_Inviting.Region,\n",
    "            TDI_TenderInviting.TenderYear = Update_Inviting.TenderYear,\n",
    "            TDI_TenderInviting.TenderQuotationType = Update_Inviting.TenderQuotationType,\n",
    "            TDI_TenderInviting.[Status] = Update_Inviting.[Status],\n",
    "            TDI_TenderInviting.Note_AIS = Update_Inviting.Note_AIS,\n",
    "            TDI_TenderInviting.Source_Update = Update_Inviting.Source_Update \n",
    "        FROM TDI_TenderInviting\n",
    "        INNER JOIN Update_Inviting\n",
    "        ON TDI_TenderInviting.ID = Update_Inviting.ID\n",
    "        DROP TABLE Update_Inviting\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (r'C:\\\\')\n",
    "files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tender Data Insight_Danapha.xlsx_Result\n",
      "Tender Data Insight_JnJ.xlsx_Result\n",
      "Tender Data Insight_Venlafaxine.xlsx_Result\n",
      "PLEASE DELETE ALL FILES IN THE UPDATE FILE\n"
     ]
    }
   ],
   "source": [
    "types = ['Result','Inviting']\n",
    "for type in types:\n",
    "    connection_url = URL.create('mssql+pyodbc', query={'odbc_connect': cnxn_str})\n",
    "    enigne = create_engine(connection_url, module=pyodbc)\n",
    "    for f in files:\n",
    "        try:\n",
    "            #read excel file for Result/Inviting sheet  \n",
    "            update = pd.read_excel(path + f,sheet_name=type)\n",
    "            #EDA\n",
    "            update.drop_duplicates(subset=['ID'], inplace=True)\n",
    "            update.rename(columns={'ID':'id'},inplace=True)\n",
    "            update[f'key_update_{type}'] = update['Quota(SmallestUnit)'].astype(str) + '_' + update['QuotationID'].astype(str)\n",
    "            #update = update[update['Include/Exclude'].isna()]\n",
    "            update['Status'] = f'Update_{datetime.now().strftime(\"%Y%m%d\")}'\n",
    "            update['Source_Update'] = f'{datetime.now().strftime(\"%Y%m%d\")}_' + f[:-5]\n",
    "            update.drop(['ClosedDate','ResultDate','ValidTo'], axis=1, inplace=True)\n",
    "\n",
    "            if type == 'Result':\n",
    "                #EDA\n",
    "                update[['Quota(SmallestUnit)','Price','Value']] = update[['Quota(SmallestUnit)','Price','Value']].astype('int',errors='ignore')\n",
    "                update = update.astype('string')\n",
    "                update = update.replace(['0'], np.nan)\n",
    "                #import data to sql to take out specific dataset that need to update\n",
    "                update.to_sql(f'Update_{type}', con=enigne, if_exists='replace', index=False)\n",
    "                #export desired dataset to python\n",
    "                sql = pd.read_sql(sql_Result, cnxn)\n",
    "                #create key ID to verify data accuracy that is about to be updated to sql database\n",
    "                sql[f'key_sql_{type}'] = sql['quota(smallestunit)'].astype(str) + '_' + sql['quotationid'].astype(str)\n",
    "                sql[f'key_sql_{type}'] = sql[f'key_sql_{type}'].str.replace('None','0', regex=True)\n",
    "                update = pd.merge(update,sql[['id',f'key_sql_{type}']],on='id',how='left')\n",
    "                update = update[update[f'key_sql_{type}'].notna()]\n",
    "                update['match'] = np.where(update[f'key_sql_{type}'] == update[f'key_update_{type}'],1,0)\n",
    "                #if data accuracy equal or bigger than 90% then keeping the whole dataset or else delete inaccurcy records\n",
    "                if update.match.sum()/update.id.count() < 0.9:\n",
    "                    update = update[update['match']==1]\n",
    "                #import the verified dataset to SQL\n",
    "                update.to_sql(f'Update_{type}', con=enigne, if_exists='replace', index=False)\n",
    "                #update the verifed dataset to SQL databse\n",
    "                cursor.execute(sql_update_Result)\n",
    "                cnxn.commit()\n",
    "            \n",
    "            elif type == 'Inviting':\n",
    "                #EDA\n",
    "                update['Quota(SmallestUnit)'] = update['Quota(SmallestUnit)'].astype('int',errors='ignore')\n",
    "                update = update.astype('string')\n",
    "                update = update.replace(['0'], np.nan)\n",
    "                #import data to sql to take out specific dataset that need to update\n",
    "                update.to_sql(f'Update_{type}', con=enigne, if_exists='replace', index=False)\n",
    "                #export desired dataset to python\n",
    "                sql = pd.read_sql(sql_Inviting, cnxn)\n",
    "                #create key ID to verify data accuracy that is about to be updated to sql database\n",
    "                sql[f'key_sql_{type}'] = sql['quota(smallestunit)'].astype(str) + '_' + sql['quotationid']\n",
    "                sql[f'key_sql_{type}'] = sql[f'key_sql_{type}'].str.replace('None','0', regex=True)\n",
    "                update = pd.merge(update,sql[['id',f'key_sql_{type}']],on='id',how='left')\n",
    "                update = update[update[f'key_sql_{type}'].notna()]\n",
    "                update['match'] = np.where(update[f'key_sql_{type}'] == update[f'key_update_{type}'],1,0)\n",
    "                #if data accuracy equal or bigger than 90% then keeping the whole dataset or else delete inaccurcy records\n",
    "                if update.match.sum()/update.id.count() < 0.9:\n",
    "                    update = update[update['match']==1]\n",
    "                #import the verified dataset to SQL\n",
    "                update.to_sql(f'Update_{type}', con=enigne, if_exists='replace', index=False)\n",
    "                #update the verifed dataset to SQL databse\n",
    "                cursor.execute(sql_update_Inviting)\n",
    "                cnxn.commit()\n",
    "                \n",
    "            print(f + '_' + type)\n",
    "\n",
    "        except ValueError:\n",
    "            pass\n",
    "print('PLEASE DELETE ALL FILES IN THE UPDATE FILE')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
